{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8e8def",
   "metadata": {
    "papermill": {
     "duration": 0.005294,
     "end_time": "2024-03-05T08:07:11.595473",
     "exception": false,
     "start_time": "2024-03-05T08:07:11.590179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pix2Pix Introduction :    \n",
    "   Pix2Pix is a generative adversarial network (GAN) architecture designed for image-to-image translation tasks. The Pix2Pix model consists of a generator and a discriminator that work adversarially to generate realistic images from one domain to another. The model is trained on paired datasets, where each input image from the source domain has a corresponding target image in the desired target domain.\n",
    "\n",
    "   This Pix2Pix network is focussed on translating images from the Infrared(IR) Domain to Passive Microwave Rainfall(PMR) domain, the Pix2Pix model would be trained on pairs of Infrared images and their corresponding ground truth Passive Microwave Rainfall Images. The goal is to teach the model to generate accurate and realistic PMR images from Infrared inputs.\n",
    "\n",
    "Here's a simplified outline of the process:\n",
    "\n",
    "**Data Preparation:**\n",
    "\n",
    "Gathering a dataset of paired images where each Infrared image has a corresponding ground truth Passive Microwave Rainfall Image.\n",
    "\n",
    "**Generator:**\n",
    "\n",
    "The generator takes Infrared images as input and attempts to generate images that resemble the target domain (Passive Microwave Rainfall Images).\n",
    "It typically consists of encoder-decoder blocks to capture and transform features from one domain to another.\n",
    "\n",
    "**Discriminator:**\n",
    "\n",
    "The discriminator evaluates the realism of the generated images by comparing them to real images from the target domain.\n",
    "It aims to distinguish between real and generated images.\n",
    "\n",
    "**Adversarial Training:**\n",
    "\n",
    "The generator and discriminator are trained adversarially. The generator aims to fool the discriminator into thinking its generated images are real.\n",
    "The discriminator is trained to correctly distinguish between real and generated images.\n",
    "\n",
    "**Loss Functions:**\n",
    "\n",
    "The generator is optimized using adversarial loss, which encourages generating realistic images.\n",
    "Additional perceptual loss functions, like L1 or L2 loss, may be used to ensure pixel-wise similarity between generated and target images.\n",
    "\n",
    "**Evaluation:**\n",
    "\n",
    "The model is evaluated on a separate validation set to ensure its ability to generalize to new, unseen data.\n",
    "Common evaluation metrics include PSNR, SSIM, and domain-specific metrics.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74509fef",
   "metadata": {
    "papermill": {
     "duration": 0.004571,
     "end_time": "2024-03-05T08:07:11.605273",
     "exception": false,
     "start_time": "2024-03-05T08:07:11.600702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation - Preprocessing the images :\n",
    "    The dataset used has paired images, so the image has to be split into the corresponding halves pertaining to each domain (Infrared and Passive Micorwave Rainfall).\n",
    "    The split images are to be resized and stored separately\n",
    "    The processed images are then stored into a npz file for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fd4f63",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-05T08:07:11.617012Z",
     "iopub.status.busy": "2024-03-05T08:07:11.616418Z",
     "iopub.status.idle": "2024-03-05T08:07:25.906357Z",
     "shell.execute_reply": "2024-03-05T08:07:25.905153Z"
    },
    "papermill": {
     "duration": 14.298951,
     "end_time": "2024-03-05T08:07:25.909076",
     "exception": false,
     "start_time": "2024-03-05T08:07:11.610125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 08:07:14.001725: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 08:07:14.001846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 08:07:14.160835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "(201, 201, 3)\n",
      "(256, 256, 3)\n",
      "Loaded (10, 256, 256, 3) (10, 256, 256, 3)\n",
      "Saved dataset:  pmwtoir1_256.npz\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from numpy import savez_compressed\n",
    "# Define the path to your directory\n",
    "directory = '/kaggle/input/tcirrp-dataset/TCIRRP/train0.01k'\n",
    "\n",
    "# Get a list of all the file paths\n",
    "image_paths = [os.path.join(directory, img) for img in os.listdir(directory)]\n",
    "\n",
    "# Load the images in grayscale\n",
    "images = np.array([cv2.imread(img_path) for img_path in image_paths])\n",
    "\n",
    "pmw=[]\n",
    "ir=[]\n",
    "# cv2.imshow('image',images[0])\n",
    "for i in range(len(images)):\n",
    "    image1 = images[i][0:201, 0:201]\n",
    "    image2 = images[i][0:201,201:402]\n",
    "    print(image1.shape)\n",
    "    image1=cv2.resize(image1,(256,256))\n",
    "    image2=cv2.resize(image2,(256,256))\n",
    "    print(image1.shape)\n",
    "    image1=image1.reshape(256,256,3)\n",
    "    image2=image2.reshape(256,256,3)\n",
    "    pmw.append(image1)\n",
    "    ir.append(image2)\n",
    "pmw=np.array(pmw)\n",
    "ir=np.array(ir)\n",
    "\n",
    "# Now `images` is a list of numpy arrays representing your images in grayscale\n",
    "print(\"Loaded\",pmw.shape,ir.shape)\n",
    "# # save as compressed numpy array\n",
    "filename = 'pmwtoir1_256.npz'\n",
    "savez_compressed(filename,ir,pmw)\n",
    "print('Saved dataset: ', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df325a",
   "metadata": {
    "papermill": {
     "duration": 0.004725,
     "end_time": "2024-03-05T08:07:25.919328",
     "exception": false,
     "start_time": "2024-03-05T08:07:25.914603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146624a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T08:07:25.932000Z",
     "iopub.status.busy": "2024-03-05T08:07:25.930781Z",
     "iopub.status.idle": "2024-03-05T08:07:25.953779Z",
     "shell.execute_reply": "2024-03-05T08:07:25.952602Z"
    },
    "papermill": {
     "duration": 0.031505,
     "end_time": "2024-03-05T08:07:25.955902",
     "exception": false,
     "start_time": "2024-03-05T08:07:25.924397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    " # weight initialization\n",
    " init = RandomNormal(stddev=0.02)\n",
    " # source image input\n",
    " in_src_image = Input(shape=image_shape)\n",
    " # target image input\n",
    " in_target_image = Input(shape=image_shape)\n",
    " # concatenate images channel-wise\n",
    " merged = Concatenate()([in_src_image, in_target_image])\n",
    " # C64\n",
    " d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    " d = LeakyReLU(alpha=0.2)(d)\n",
    " # C128\n",
    " d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    " d = BatchNormalization()(d)\n",
    " d = LeakyReLU(alpha=0.2)(d)\n",
    " # C256\n",
    " d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    " d = BatchNormalization()(d)\n",
    " d = LeakyReLU(alpha=0.2)(d)\n",
    " # C512\n",
    " d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    " d = BatchNormalization()(d)\n",
    " d = LeakyReLU(alpha=0.2)(d)\n",
    " # second last output layer\n",
    " d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    " d = BatchNormalization()(d)\n",
    " d = LeakyReLU(alpha=0.2)(d)\n",
    " # patch output\n",
    " d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    " patch_out = Activation('sigmoid')(d)\n",
    " # define model\n",
    " model = Model([in_src_image, in_target_image], patch_out)\n",
    " # compile model\n",
    " opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    " model.outputs  \n",
    " model.summary()\n",
    " model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights = [0.5])          #was this the source of error ?\n",
    " return model\n",
    " \n",
    "# define an encoder block\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    " # weight initialization\n",
    " init = RandomNormal(stddev=0.02)\n",
    " # add downsampling layer\n",
    " g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    " # conditionally add batch normalization\n",
    " if batchnorm:\n",
    "   g = BatchNormalization()(g, training=True)\n",
    " # leaky relu activation\n",
    " g = LeakyReLU(alpha=0.2)(g)\n",
    " return g\n",
    " \n",
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    " # weight initialization\n",
    " init = RandomNormal(stddev=0.02)\n",
    " # add upsampling layer\n",
    " g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    " # add batch normalization\n",
    " g = BatchNormalization()(g, training=True)\n",
    " # conditionally add dropout\n",
    " if dropout:\n",
    "   g = Dropout(0.5)(g, training=True)\n",
    " # merge with skip connection\n",
    " g = Concatenate()([g, skip_in])\n",
    " # relu activation\n",
    " g = Activation('relu')(g)\n",
    " return g\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(256,256,3)):\n",
    " # weight initialization\n",
    " init = RandomNormal(stddev=0.02)\n",
    " # image input\n",
    " in_image = Input(shape=image_shape)\n",
    " # encoder model\n",
    " e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    " e2 = define_encoder_block(e1, 128)\n",
    " e3 = define_encoder_block(e2, 256)\n",
    " e4 = define_encoder_block(e3, 512)\n",
    " e5 = define_encoder_block(e4, 512)\n",
    " e6 = define_encoder_block(e5, 512)\n",
    " e7 = define_encoder_block(e6, 512)\n",
    " # bottleneck, no batch norm and relu\n",
    " b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    " b = Activation('relu')(b)\n",
    " # decoder model\n",
    " d1 = decoder_block(b, e7, 512)\n",
    " d2 = decoder_block(d1, e6, 512)\n",
    " d3 = decoder_block(d2, e5, 512)\n",
    " d4 = decoder_block(d3, e4, 512, dropout=False)\n",
    " d5 = decoder_block(d4, e3, 256, dropout=False)\n",
    " d6 = decoder_block(d5, e2, 128, dropout=False)\n",
    " d7 = decoder_block(d6, e1, 64, dropout=False)\n",
    " # output\n",
    " g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    " out_image = Activation('tanh')(g)\n",
    " # define model\n",
    " model = Model(in_image, out_image)\n",
    " return model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa0f4c",
   "metadata": {
    "papermill": {
     "duration": 0.004722,
     "end_time": "2024-03-05T08:07:25.965790",
     "exception": false,
     "start_time": "2024-03-05T08:07:25.961068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the composite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295b8291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T08:07:25.977779Z",
     "iopub.status.busy": "2024-03-05T08:07:25.977097Z",
     "iopub.status.idle": "2024-03-05T08:07:25.984152Z",
     "shell.execute_reply": "2024-03-05T08:07:25.982970Z"
    },
    "papermill": {
     "duration": 0.015283,
     "end_time": "2024-03-05T08:07:25.986300",
     "exception": false,
     "start_time": "2024-03-05T08:07:25.971017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    " # make weights in the discriminator not trainable\n",
    " for layer in d_model.layers:\n",
    "   if not isinstance(layer, BatchNormalization):\n",
    "      layer.trainable = False\n",
    " # define the source image\n",
    " in_src = Input(shape=image_shape)\n",
    " # connect the source image to the generator input\n",
    " gen_out = g_model(in_src)\n",
    " # connect the source input and generator output to the discriminator input\n",
    " dis_out = d_model([in_src, gen_out])\n",
    " # src image as input, generated image and classification output\n",
    " model = Model(in_src, [dis_out, gen_out])\n",
    " # compile model\n",
    " opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    " model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1.0,100.0])\n",
    " return model\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549c278",
   "metadata": {
    "papermill": {
     "duration": 0.004823,
     "end_time": "2024-03-05T08:07:25.996248",
     "exception": false,
     "start_time": "2024-03-05T08:07:25.991425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining helper functions for easy image access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7d9ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T08:07:26.008444Z",
     "iopub.status.busy": "2024-03-05T08:07:26.008072Z",
     "iopub.status.idle": "2024-03-05T08:07:26.015655Z",
     "shell.execute_reply": "2024-03-05T08:07:26.014589Z"
    },
    "papermill": {
     "duration": 0.016499,
     "end_time": "2024-03-05T08:07:26.017874",
     "exception": false,
     "start_time": "2024-03-05T08:07:26.001375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    " # load compressed arrays\n",
    " data = load(filename)\n",
    " # unpack arrays\n",
    " X1, X2 = data['arr_0'], data['arr_1']\n",
    " # scale from [0,255] to [-1,1]\n",
    " X1 = (X1 - 127.5) / 127.5\n",
    " X2 = (X2 - 127.5) / 127.5\n",
    " return [X1, X2]\n",
    " \n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    " # unpack dataset\n",
    " trainA, trainB = dataset\n",
    " # choose random instances\n",
    " ix = randint(0, trainA.shape[0], n_samples)\n",
    " # retrieve selected images\n",
    " X1, X2 = trainA[ix], trainB[ix]\n",
    " # generate 'real' class labels (1)\n",
    " y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    " return [X1, X2], y\n",
    " \n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    " # generate fake instance\n",
    " X = g_model.predict(samples)\n",
    " # create 'fake' class labels (0)\n",
    " y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    " return X, y\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81870a3a",
   "metadata": {
    "papermill": {
     "duration": 0.004849,
     "end_time": "2024-03-05T08:07:26.027957",
     "exception": false,
     "start_time": "2024-03-05T08:07:26.023108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Summarizing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c500f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T08:07:26.040001Z",
     "iopub.status.busy": "2024-03-05T08:07:26.039492Z",
     "iopub.status.idle": "2024-03-05T08:07:26.048322Z",
     "shell.execute_reply": "2024-03-05T08:07:26.047589Z"
    },
    "papermill": {
     "duration": 0.017165,
     "end_time": "2024-03-05T08:07:26.050232",
     "exception": false,
     "start_time": "2024-03-05T08:07:26.033067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, dataset, n_samples=3):\n",
    " # select a sample of input images\n",
    " [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
    " # generate a batch of fake samples\n",
    " X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    " # scale all pixels from [-1,1] to [0,1]\n",
    " X_realA = (X_realA + 1) / 2.0\n",
    " X_realB = (X_realB + 1) / 2.0\n",
    " X_fakeB = (X_fakeB + 1) / 2.0\n",
    " # plot real source images\n",
    " for i in range(n_samples):\n",
    "   pyplot.subplot(3, n_samples, 1 + i)\n",
    "   pyplot.axis('off')\n",
    "   pyplot.imshow(X_realA[i])\n",
    " # plot generated target image\n",
    " for i in range(n_samples):\n",
    "   pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "   pyplot.axis('off')\n",
    "   pyplot.imshow(X_fakeB[i])\n",
    " # plot real target image\n",
    " for i in range(n_samples):\n",
    "   pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "   pyplot.axis('off')\n",
    "   pyplot.imshow(X_realB[i])\n",
    " # save plot to file\n",
    " filename1 = 'plot_%06d.png' % (step+1)\n",
    " pyplot.savefig(filename1)\n",
    " pyplot.close()\n",
    " # save the generator model\n",
    " filename2 = 'model_%06d.h5' % (step+1)\n",
    " g_model.save(filename2)\n",
    " print('>Saved: %s and %s' % (filename1, filename2))\n",
    "\n",
    "def save_models(step, g_model_AtoB):\n",
    "\t# save the first generator model\n",
    "\tfilename1 = 'g_model_AtoB_%06d.h5' % (step+1)\n",
    "\tg_model_AtoB.save(filename1)\n",
    "\t# save the second generator model\n",
    "\tprint('>Saved:%s' % (filename1))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c149f",
   "metadata": {
    "papermill": {
     "duration": 0.004835,
     "end_time": "2024-03-05T08:07:26.060582",
     "exception": false,
     "start_time": "2024-03-05T08:07:26.055747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bbd18f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T08:07:26.072349Z",
     "iopub.status.busy": "2024-03-05T08:07:26.071972Z",
     "iopub.status.idle": "2024-03-05T08:07:29.391925Z",
     "shell.execute_reply": "2024-03-05T08:07:29.390339Z"
    },
    "papermill": {
     "duration": 3.328007,
     "end_time": "2024-03-05T08:07:29.393725",
     "exception": true,
     "start_time": "2024-03-05T08:07:26.065718",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (10, 256, 256, 3) (10, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ leaky_re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ leaky_re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> │ leaky_re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m6\u001b[0m)                │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m6,208\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m524,544\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m2,097,664\u001b[0m │ leaky_re_lu_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m4,194,816\u001b[0m │ leaky_re_lu_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m) │      \u001b[38;5;34m8,193\u001b[0m │ leaky_re_lu_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,968,257</span> (26.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,968,257\u001b[0m (26.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,965,441</span> (26.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,965,441\u001b[0m (26.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,816\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When there is only a single output, the `loss_weights` argument must be a Python float. Received instead: loss_weights=[0.5] of type <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m gan_model \u001b[38;5;241m=\u001b[39m define_gan(g_model, d_model, image_shape)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(d_model, g_model, gan_model, dataset, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m    X_fakeB, y_fake \u001b[38;5;241m=\u001b[39m generate_fake_samples(g_model, X_realA, n_patch)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# update discriminator for real samples\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m    d_loss1 \u001b[38;5;241m=\u001b[39m \u001b[43md_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_realA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_realB\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# update discriminator for generated samples\u001b[39;00m\n\u001b[1;32m     20\u001b[0m    d_loss2 \u001b[38;5;241m=\u001b[39m d_model\u001b[38;5;241m.\u001b[39mtrain_on_batch([X_realA, X_fakeB], y_fake)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:549\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[0;32m--> 549\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:117\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 117\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    121\u001b[0m     outputs,\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    123\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:105\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:59\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[0;32m---> 59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_tracker\u001b[38;5;241m.\u001b[39mupdate_state(loss)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/trainer.py:321\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    319\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/compile_utils.py:606\u001b[0m, in \u001b[0;36mCompileLoss.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m--> 606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/compile_utils.py:619\u001b[0m, in \u001b[0;36mCompileLoss.call\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_y(y_true)\n\u001b[1;32m    622\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_y(y_pred)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/compile_utils.py:485\u001b[0m, in \u001b[0;36mCompileLoss.build\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_weights:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_weights, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m--> 485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    486\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen there is only a single output, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`loss_weights` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be a Python float. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived instead: loss_weights=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_weights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(loss_weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m         )\n\u001b[1;32m    492\u001b[0m     flat_loss_weights\u001b[38;5;241m.\u001b[39mappend(loss_weights)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: When there is only a single output, the `loss_weights` argument must be a Python float. Received instead: loss_weights=[0.5] of type <class 'list'>"
     ]
    }
   ],
   "source": [
    " \n",
    "# train pix2pix models\n",
    "def train(d_model, g_model, gan_model, dataset, n_epochs=10, n_batch=1):\n",
    " # determine the output square shape of the discriminator\n",
    " n_patch = d_model.output_shape[1]\n",
    " # unpack dataset\n",
    " trainA, trainB = dataset\n",
    " # calculate the number of batches per training epoch\n",
    " bat_per_epo = int(len(trainA) / n_batch)\n",
    " # calculate the number of training iterations\n",
    " n_steps = bat_per_epo * n_epochs\n",
    " # manually enumerate epochs\n",
    " for i in range(n_steps):\n",
    " # select a batch of real samples\n",
    "    [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    " # generate a batch of fake samples\n",
    "    X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    " # update discriminator for real samples\n",
    "    d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    " # update discriminator for generated samples\n",
    "    d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    " # update the generator\n",
    "    g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    " # summarize performance\n",
    "    print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    " # summarize model performance\n",
    "    if (i+1) % (bat_per_epo * 10) == 0:\n",
    "        summarize_performance(i, g_model, dataset)\n",
    "    save_models(i, g_model)\n",
    " \n",
    "# load image data\n",
    "dataset = load_real_samples('pmwtoir1_256.npz')\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "# train model\n",
    "train(d_model, g_model, gan_model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2b474",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# **Defining the metrics**\n",
    "\n",
    "Key metrics used to ensure that the generated images are similar to the ground truth images are:\n",
    "\n",
    "- **RMSE (Root Mean Squared Error):**\n",
    "  - Measures the average magnitude of pixel-wise differences between the generated and target images.\n",
    "  - Lower RMSE values indicate better pixel-level similarity.\n",
    "  - Sensitive to outliers and can be influenced by extreme values.\n",
    "\n",
    "- **PSNR (Peak Signal-to-Noise Ratio):**\n",
    "  - Quantifies the quality of the generated image by comparing it to the target image.\n",
    "  - Higher PSNR values indicate better image quality.\n",
    "  - It is a logarithmic scale, and a higher PSNR is associated with lower perceptual differences.\n",
    "\n",
    "- **CC (Pearson Correlation Coefficient):**\n",
    "  - Assesses the linear relationship between pixel intensities of the generated and target images.\n",
    "  - A value close to 1 indicates a strong positive correlation, implying high similarity.\n",
    "  - Not sensitive to intensity shifts but assumes a linear relationship.\n",
    "\n",
    "- **SSIM (Structural Similarity Index):**\n",
    "  - Evaluates the structural information and textures in the images.\n",
    "  - Takes into account luminance, contrast, and structure.\n",
    "  - SSIM values range from -1 to 1, where 1 indicates perfect similarity.\n",
    "  - Multiscale and considers local features, making it suitable for assessing perceptual quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc90f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T07:49:45.824179Z",
     "iopub.status.busy": "2024-03-05T07:49:45.823730Z",
     "iopub.status.idle": "2024-03-05T07:49:45.836338Z",
     "shell.execute_reply": "2024-03-05T07:49:45.834730Z",
     "shell.execute_reply.started": "2024-03-05T07:49:45.824144Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Performance metrics \n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_rmse(target, prediction):\n",
    "    return np.sqrt(((prediction - target) ** 2).mean())\n",
    "\n",
    "def calculate_psnr(target, prediction):\n",
    "    return psnr(target, prediction, data_range=prediction.max() - prediction.min())\n",
    "\n",
    "def calculate_cc(target, prediction):\n",
    "    return pearsonr(target.flatten(), prediction.flatten())[0]\n",
    "\n",
    "def calculate_ssim(target, prediction):\n",
    "    # Use a smaller window size for SSIM calculation\n",
    "    return ssim(target, prediction, win_size=3, multichannel=True, data_range=prediction.max() - prediction.min())\n",
    "\n",
    "def calculate_metrics(targets,predictions,n_images):\n",
    "    rmse_values = np.zeros(n_images)\n",
    "    psnr_values = np.zeros(n_images)\n",
    "    cc_values = np.zeros(n_images)\n",
    "    ssim_values = np.zeros(n_images)\n",
    "\n",
    "    for i in range(n_images):\n",
    "        target = targets[i]\n",
    "        prediction = predictions[i]\n",
    "\n",
    "        rmse_values[i] = calculate_rmse(target, prediction)\n",
    "        psnr_values[i] = calculate_psnr(target, prediction)\n",
    "        cc_values[i] = calculate_cc(target, prediction)\n",
    "        ssim_values[i] = calculate_ssim(target, prediction)\n",
    "\n",
    "    # Create a DataFrame to display the results\n",
    "    df = pd.DataFrame({\n",
    "        'Image': [f'Image {i+1}' for i in range(n_images)],\n",
    "        'RMSE': rmse_values,\n",
    "        'PSNR': psnr_values,\n",
    "        'CC': cc_values,\n",
    "        'SSIM': ssim_values\n",
    "    })\n",
    "\n",
    "    # Add a row for average values\n",
    "    #df.loc['Average'] = df.mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f1ba0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Loading the test data from already saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905f28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T07:49:46.911570Z",
     "iopub.status.busy": "2024-03-05T07:49:46.911113Z",
     "iopub.status.idle": "2024-03-05T07:49:48.314139Z",
     "shell.execute_reply": "2024-03-05T07:49:48.312930Z",
     "shell.execute_reply.started": "2024-03-05T07:49:46.911532Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "data = load(\"/kaggle/input/100-images-metrics/pmwtoir1_256_metrics_100.npz\")\n",
    "# unpack arrays\n",
    "X1, X2 = data['arr_0'], data['arr_1']\n",
    "# scale from [0,255] to [-1,1]\n",
    "real = (X1 - 127.5) / 127.5\n",
    "fake = (X2 - 127.5) / 127.5\n",
    "print(real.shape,'   ',real.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524ed4f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Individual image metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a54053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T07:51:21.751200Z",
     "iopub.status.busy": "2024-03-05T07:51:21.750736Z",
     "iopub.status.idle": "2024-03-05T07:51:29.820511Z",
     "shell.execute_reply": "2024-03-05T07:51:29.819290Z",
     "shell.execute_reply.started": "2024-03-05T07:51:21.751163Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = calculate_metrics(real,fake,100)\n",
    "result_df.drop('Image',axis=1,inplace = True)\n",
    "metrics_100_df = result_df\n",
    "metrics_100_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b6c06c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Metrics summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93bd03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T07:51:16.732449Z",
     "iopub.status.busy": "2024-03-05T07:51:16.731989Z",
     "iopub.status.idle": "2024-03-05T07:51:16.742134Z",
     "shell.execute_reply": "2024-03-05T07:51:16.740401Z",
     "shell.execute_reply.started": "2024-03-05T07:51:16.732414Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_100_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4506938,
     "sourceId": 7716902,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4540936,
     "sourceId": 7763878,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.070243,
   "end_time": "2024-03-05T08:07:31.917869",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-05T08:07:08.847626",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
